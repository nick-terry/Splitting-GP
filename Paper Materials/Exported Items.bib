
@inproceedings{gardner_gpytorch_2018,
	address = {Montr√©al, Canada},
	series = {{NIPS}'18},
	title = {{GPyTorch}: blackbox matrix-matrix {Gaussian} process inference with {GPU} acceleration},
	shorttitle = {{GPyTorch}},
	abstract = {Despite advances in scalable models, the inference tools used for Gaussian processes (GPs) have yet to fully capitalize on developments in computing hardware. We present an efficient and general approach to GP inference based on Blackbox Matrix-Matrix multiplication (BBMM). BBMM inference uses a modified batched version of the conjugate gradients algorithm to derive all terms for training and inference in a single call. BBMM reduces the asymptotic complexity of exact GP inference from O(n3) to O(n2). Adapting this algorithm to scalable approximations and complex GP models simply requires a routine for efficient matrix-matrix multiplication with the kernel and its derivative. In addition, BBMM uses a specialized preconditioner to substantially speed up convergence. In experiments we show that BBMM effectively uses GPU hardware to dramatically accelerate both exact GP inference and scalable approximations. Additionally, we provide GPyTorch, a software platform for scalable GP inference via BBMM, built on PyTorch.},
	urldate = {2020-04-26},
	booktitle = {Proceedings of the 32nd {International} {Conference} on {Neural} {Information} {Processing} {Systems}},
	publisher = {Curran Associates Inc.},
	author = {Gardner, Jacob R. and Pleiss, Geoff and Bindel, David and Weinberger, Kilian Q. and Wilson, Andrew Gordon},
	month = dec,
	year = {2018},
	pages = {7587--7597},
	file = {Full Text PDF:C\:\\Users\\pnter\\Zotero\\storage\\I5RA55ZM\\Gardner et al. - 2018 - GPyTorch blackbox matrix-matrix Gaussian process .pdf:application/pdf}
}