
@article{gramacy_bayesian_2008,
	title = {Bayesian {Treed} {Gaussian} {Process} {Models} {With} an {Application} to {Computer} {Modeling}},
	volume = {103},
	issn = {0162-1459},
	url = {https://amstat.tandfonline.com/doi/abs/10.1198/016214508000000689},
	doi = {10.1198/016214508000000689},
	abstract = {Motivated by a computer experiment for the design of a rocket booster, this article explores nonstationary modeling methodologies that couple stationary Gaussian processes with treed partitioning. Partitioning is a simple but effective method for dealing with nonstationarity. The methodological developments and statistical computing details that make this approach efficient are described in detail. In addition to providing an analysis of the rocket booster simulator, we show that our approach is effective in other arenas as well.},
	number = {483},
	urldate = {2020-05-25},
	journal = {Journal of the American Statistical Association},
	author = {Gramacy, Robert B and Lee, Herbert K. H},
	month = sep,
	year = {2008},
	note = {Publisher: Taylor \& Francis},
	pages = {1119--1130},
	file = {Full Text:C\:\\Users\\pnter\\Zotero\\storage\\VYAII93C\\Gramacy and Lee - 2008 - Bayesian Treed Gaussian Process Models With an App.pdf:application/pdf;Snapshot:C\:\\Users\\pnter\\Zotero\\storage\\ZJXA87J8\\016214508000000689.html:text/html}
}

@article{gramacy_local_2015,
	title = {Local {Gaussian} {Process} {Approximation} for {Large} {Computer} {Experiments}},
	volume = {24},
	issn = {1061-8600},
	url = {https://doi.org/10.1080/10618600.2014.914442},
	doi = {10.1080/10618600.2014.914442},
	abstract = {We provide a new approach to approximate emulation of large computer experiments. By focusing expressly on desirable properties of the predictive equations, we derive a family of local sequential design schemes that dynamically define the support of a Gaussian process predictor based on a local subset of the data. We further derive expressions for fast sequential updating of all needed quantities as the local designs are built up iteratively. Then we show how independent application of our local design strategy across the elements of a vast predictive grid facilitates a trivially parallel implementation. The end result is a global predictor able to take advantage of modern multicore architectures, providing a nonstationary modeling feature as a bonus. We demonstrate our method on two examples using designs with thousands of data points, and compare to the method of compactly supported covariances. Supplementary materials for this article are available online.},
	number = {2},
	urldate = {2020-05-25},
	journal = {Journal of Computational and Graphical Statistics},
	author = {Gramacy, Robert B. and Apley, Daniel W.},
	month = apr,
	year = {2015},
	note = {Publisher: Taylor \& Francis
\_eprint: https://doi.org/10.1080/10618600.2014.914442},
	keywords = {Active learning, Compactly supported, Covariance, Emulator, Local kriging neighborhoods, Sequential design, Sequential updating, Surrogate model},
	pages = {561--578},
	file = {Full Text PDF:C\:\\Users\\pnter\\Zotero\\storage\\KXHNTLJN\\Gramacy and Apley - 2015 - Local Gaussian Process Approximation for Large Com.pdf:application/pdf;Snapshot:C\:\\Users\\pnter\\Zotero\\storage\\QNKIBBZF\\10618600.2014.html:text/html}
}

@phdthesis{gramacy_bayesian_2005,
	type = {Doctoral},
	title = {Bayesian {Treed} {Gaussian} {Process} {Models}},
	url = {https://bobby.gramacy.com/prepo/gra2005-02.pdf},
	urldate = {2020-05-25},
	school = {University of California, Santa Cruz},
	author = {Gramacy, Robert B},
	year = {2005},
	file = {gra2005-02.pdf:C\:\\Users\\pnter\\Zotero\\storage\\LKLF6R4A\\gra2005-02.pdf:application/pdf}
}
